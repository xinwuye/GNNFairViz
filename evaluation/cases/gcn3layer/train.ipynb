{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "# from dgl import AddSelfLoop\n",
    "# from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset\n",
    "\n",
    "# for metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_size, hid_size, out_size, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        assert num_layers >= 2, \"Number of layers should be at least 2.\"\n",
    "        # first layer\n",
    "        self.layers.append(dglnn.GraphConv(in_size, hid_size, activation=F.relu))\n",
    "        # hidden layers\n",
    "        for _ in range(1, num_layers-1):\n",
    "            self.layers.append(dglnn.GraphConv(hid_size, hid_size, activation=F.relu))\n",
    "        # output layer\n",
    "        self.layers.append(dglnn.GraphConv(hid_size, out_size))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = features\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:  # apply dropout after the first layer\n",
    "                h = self.dropout(h)\n",
    "            h = layer(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_norm(features):\n",
    "    min_values = features.min(axis=0)[0]\n",
    "    max_values = features.max(axis=0)[0]\n",
    "    return 2*(features - min_values).div(max_values-min_values) - 1\n",
    "\n",
    "\n",
    "def train(g, features, labels, masks, model, epochs=2000, patience=1500, save_path='best_model.pth'):\n",
    "    train_mask = masks[0]\n",
    "    val_mask = masks[1]\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        model.train()\n",
    "        logits = model(g, features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_acc, val_f1 = evaluate(g, features, labels, val_mask, model)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch:05d} | Loss {loss.item():.4f} | Val Accuracy {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping and model saving\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter == patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "\n",
    "def evaluate(g, features, labels, mask, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)\n",
    "        predictions = torch.argmax(logits[mask], dim=1)\n",
    "        acc = (predictions == labels[mask]).float().mean()\n",
    "        f1 = f1_score(labels[mask].cpu(), predictions.cpu(), average='weighted')\n",
    "    return acc.item(), f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')  # Adds the EUG directory to the PYTHONPATH\n",
    "\n",
    "from datasets import Bail\n",
    "bail = Bail()\n",
    "adj, features, idx_train, idx_val, idx_test, labels, sens, feat_names, sens_names \\\n",
    "    = bail.adj(), bail.features(), bail.idx_train(), bail.idx_val(), \\\n",
    "      bail.idx_test(), bail.labels(), bail.sens(), bail.feat_names(), bail.sens_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Nba\n",
    "nba = Nba()\n",
    "adj, features, idx_train, idx_val, idx_test, labels, sens, feat_names, sens_names \\\n",
    "    = nba.adj(), nba.features(), nba.idx_train(), nba.idx_val(), \\\n",
    "      nba.idx_test(), nba.labels(), nba.sens(), nba.feat_names(), nba.sens_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Pokec_n\n",
    "pokec_n = Pokec_n()\n",
    "adj, features, idx_train, idx_val, idx_test, labels, sens, feat_names, sens_names \\\n",
    "    = pokec_n.adj(), pokec_n.features(), pokec_n.idx_train(), pokec_n.idx_val(), \\\n",
    "      pokec_n.idx_test(), pokec_n.labels(), pokec_n.sens(), pokec_n.feat_names(), pokec_n.sens_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Pokec_z\n",
    "pokec_z = Pokec_z()\n",
    "adj, features, idx_train, idx_val, idx_test, labels, sens, feat_names, sens_names \\\n",
    "    = pokec_z.adj(), pokec_z.features(), pokec_z.idx_train(), pokec_z.idx_val(), \\\n",
    "      pokec_z.idx_test(), pokec_z.labels(), pokec_z.sens(), pokec_z.feat_names(), pokec_z.sens_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# masks = g.ndata[\"train_mask\"], g.ndata[\"val_mask\"], g.ndata[\"test_mask\"]\n",
    "# Get the source and destination node IDs\n",
    "# adj = adj.int().to(device)\n",
    "src, dst = adj.coalesce().indices()\n",
    "\n",
    "# Create the heterograph\n",
    "g = dgl.heterograph({('node', 'edge', 'node'): (src.cpu().numpy(), dst.cpu().numpy())})\n",
    "g = g.int().to(device)\n",
    "\n",
    "# convert idx_train, idx_val, idx_test to boolean masks\n",
    "train_mask = torch.zeros(adj.shape[0], dtype=torch.bool)\n",
    "val_mask = torch.zeros(adj.shape[0], dtype=torch.bool)\n",
    "test_mask = torch.zeros(adj.shape[0], dtype=torch.bool)\n",
    "train_mask[idx_train] = True\n",
    "val_mask[idx_val] = True\n",
    "test_mask[idx_test] = True\n",
    "masks = train_mask, val_mask, test_mask\n",
    "\n",
    "# normalize features\n",
    "features = feature_norm(features)\n",
    "\n",
    "features = features.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 6/2000 [00:00<00:36, 54.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 0.7337 | Val Accuracy 0.5520 | Val F1 0.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   6%|▌         | 114/2000 [00:01<00:23, 80.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00100 | Loss 0.5333 | Val Accuracy 0.7060 | Val F1 0.7068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  11%|█         | 217/2000 [00:02<00:22, 80.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00200 | Loss 0.5037 | Val Accuracy 0.7111 | Val F1 0.7112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  16%|█▌        | 316/2000 [00:03<00:20, 83.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00300 | Loss 0.4965 | Val Accuracy 0.7138 | Val F1 0.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  21%|██        | 414/2000 [00:05<00:19, 80.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00400 | Loss 0.4902 | Val Accuracy 0.7099 | Val F1 0.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  26%|██▌       | 513/2000 [00:06<00:17, 85.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00500 | Loss 0.4904 | Val Accuracy 0.7072 | Val F1 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  31%|███       | 612/2000 [00:07<00:16, 85.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00600 | Loss 0.5018 | Val Accuracy 0.7099 | Val F1 0.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  36%|███▌      | 711/2000 [00:08<00:14, 85.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00700 | Loss 0.4960 | Val Accuracy 0.7099 | Val F1 0.7103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 810/2000 [00:09<00:13, 85.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00800 | Loss 0.5011 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  45%|████▌     | 909/2000 [00:11<00:13, 83.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00900 | Loss 0.4976 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  51%|█████     | 1017/2000 [00:12<00:11, 84.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01000 | Loss 0.4922 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  56%|█████▌    | 1116/2000 [00:13<00:10, 84.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01100 | Loss 0.5002 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  61%|██████    | 1214/2000 [00:14<00:10, 75.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01200 | Loss 0.5039 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  66%|██████▌   | 1312/2000 [00:15<00:08, 77.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01300 | Loss 0.4920 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 1409/2000 [00:17<00:07, 81.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01400 | Loss 0.4823 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  76%|███████▌  | 1514/2000 [00:18<00:06, 77.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01500 | Loss 0.4915 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  81%|████████  | 1612/2000 [00:19<00:04, 84.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01600 | Loss 0.5090 | Val Accuracy 0.7096 | Val F1 0.7099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  84%|████████▎ | 1672/2000 [00:20<00:03, 82.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create GCN model\n",
    "in_size = features.shape[1]\n",
    "out_size = int(sum(labels.unique() != -1))\n",
    "model = GCN(in_size, 16, out_size).to(device)\n",
    "# model training\n",
    "print(\"Training...\")\n",
    "train(g, features, labels, masks, model, save_path='./gcn3layer_Pokecz.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GCN model\n",
    "in_size = features.shape[1]\n",
    "out_size = int(sum(labels.unique() != -1))\n",
    "model = GCN(in_size, 16, out_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "model.load_state_dict(torch.load('evaluation/cases/gcn/gcn_pokecz.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(g, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('HeterogeneousGnnExplainer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d7372a7a814d329e8dcaa9a97a936266cfde7f5b4a9b5ffdd616b725d52dd32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
